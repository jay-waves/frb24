%TODO: 审核，文献，表格格式
近期有几种$^{[2, 6, 7, 8, 9, 10]}$应用于ROS2程序的新型测试方法，它们不同于由开发
者手动构造测试样例的单元测试，而尝试自动生成ROS程序输入，并借助分析检测工具
（Sanitizer）自动监控程序内存或语义错误。它们大幅提高了针对机器人系统的测试效
率，表\ref{tab:fuzzers}将这些方法进行了比较（包括本作品），可以看出这些方法在测
试ROS程序时仍存在三个主要限制：

\textbf{限制一：}测试用例生成效率低。大部分测试方法从单一维度（即用户命令或传感
器信息）生成输入，并且生成的测试样例随机性过强，无法识别出可能高效探索程序边界的
变异维度，导致许多生成的输入无助于增加测试覆盖率。

\textbf{限制二：}程序反馈效果不佳。SMACH-Fuzz和ASTAA随机生成输入，而没有反馈和指
导；Ros2-fuzz和ROZZ参考AFL工具$^{[11]}$使用代码覆盖率作为程序反馈，但代码覆盖率
对多进程运行情况不敏感，且忽略了不同执行路径；Phys-Fuzz使用场景危险程度评分来指
导进一步生成场景，对于检测ROS2自动导航程序的避障能力效果较好，但也仅限制在了此场
景下；RoboFuzz使用语义反馈来量化机器人执行上下文的正确性，但是这种特殊语义的设计
编写需要很强专业知识。

\textbf{限制三：}自动化水平低。大部分方法都需要大量领域特定知识和手动努力来配置
输入生成规则（ASTAA和RoboFuzz），编写有关机器人行为的规格（SMACH-Fuzz和
RoboFuzz），检查执行日志（SMACH-Fuzz和Phy-Fuzz）等，这导致测试效率和便捷程度对比
传统单元测试并没有很大提高。

\begin{table}[H]
\small
\centering
\caption{最新针对ROS系统的测试技术对比}
\begin{tabular}{lccccc}
\hline
\textbf{技术名} & \textbf{输入维度}  & \textbf{反馈}& \textbf{自动化程度} & \textbf{漏洞类型} \\ \hline
SMACH-Fuzz $^{[6]}$ & 单一 & 无 & 差 & 行为错误 \\ 
Phys-Fuzz $^{[7]}$ & 单一  & 环境危险程度  & 差& 碰撞损坏 \\ 
Ros2-fuzz $^{[10]}$ & 单一  & 代码覆盖率   & 较好 & 内存漏洞 \\ 
ASTAA $^{[8]}$ & 单一 & 无 & 差 & 行为错误 \\ 
RoboFuzz $^{[9]}$ & 单一  & 语义反馈 & 较差 & 行为错误 \\ 
ROZZ $^{[2]}$ & 多维度 & 代码覆盖率 & 较好 & 内存漏洞 \\ 
本作品 & 多维度  & 代码覆盖率+流量分析 & 较好& 内存与并发漏洞 \\ \hline
\end{tabular}
\label{tab:fuzzers}
\end{table}
